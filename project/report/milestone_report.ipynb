{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting COVID-19 and General Health Misinformation\n",
    "**Authors**: Santiago von Straussburg, Kyle Parfait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Overview\n",
    "\n",
    "Our project aims to create a robust model for detecting fake health news, with a primary focus on COVID-19 misinformation. The challenge we're addressing extends beyond COVID-19 detection - we want to determine if a model trained on pandemic-specific misinformation can generalize to identify other types of misleading health claims.\n",
    "\n",
    "This problem is significant because fake health information can have serious real-world consequences. During the COVID-19 pandemic, we witnessed how misinformation about cures, treatments, and vaccines could influence public behavior and potentially harm public health. Our hypothesis is that there are underlying patterns in health misinformation that transcend specific topics - in other words, a model that successfully identifies COVID-19 falsehoods might also effectively detect misleading claims about other health issues like miracle cures or unproven treatments.\n",
    "\n",
    "If our approach successfully transfers from COVID-19 to other health misinformation, it would demonstrate that our system is not merely memorizing pandemic-specific language patterns but is actually learning meaningful characteristics of health misinformation in general. This would be a significant contribution to the ongoing battle against health-related fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We are using two primary datasets focused on COVID-19 misinformation:\n",
    "\n",
    "1. **COVID-19 Fake News Dataset** (from Kaggle): This dataset contains news articles labeled as either \"fake\" or \"real\" regarding COVID-19 information.\n",
    "\n",
    "2. **CoAID (COVID-19 Healthcare Misinformation Dataset)**: This is a diverse collection that combines news articles, social media posts, and user engagement data related to COVID-19 information, all labeled as \"fake\" or \"real\".\n",
    "\n",
    "### Data Collection Process\n",
    "\n",
    "We obtained these datasets from their respective sources:\n",
    "\n",
    "1. The COVID-19 Fake News Dataset was downloaded from Kaggle, where it was compiled by researchers collecting news articles and fact-checking their veracity during the pandemic. The data collection process involved monitoring trusted fact-checking websites such as Poynter, IFCN, and WHO Myth busters.\n",
    "\n",
    "2. The CoAID dataset was accessed through GitHub, where it was published by researchers at Pennsylvania State University. This dataset was compiled by collecting both news articles and social media content from December 2019 to July 2020, which was then labeled through a combination of fact-checking website references and expert review.\n",
    "\n",
    "### Data Challenges\n",
    "\n",
    "The collection and preparation of these datasets presented several challenges:\n",
    "\n",
    "1. **Noisy data from social media**: Social media content often contains slang, abbreviations, emoji, hashtags, and non-standard language which makes preprocessing more complex.\n",
    "\n",
    "2. **Class imbalance**: There are typically fewer examples of fake news compared to legitimate news, which can bias model training.\n",
    "\n",
    "3. **Topic specificity**: COVID-19 data contains pandemic-specific terminology (e.g., \"hydroxychloroquine\", \"remdesivir\") that may not generalize to other health topics.\n",
    "\n",
    "4. **Temporal shifts**: Misinformation evolves over time. News from early 2020 focused on different aspects than later content.\n",
    "\n",
    "5. **URL accessibility**: Some news URLs in the datasets were inaccessible or returned empty content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Our approach to detecting fake health news involves a multi-step process:\n",
    "\n",
    "### Text Preprocessing Pipeline\n",
    "\n",
    "We've implemented a robust preprocessing pipeline that handles the challenges specific to social media and news content:\n",
    "\n",
    "1. **Tokenization**: Breaking text into individual tokens (words, punctuation)\n",
    "2. **Lowercasing**: Converting all text to lowercase to reduce dimensionality\n",
    "3. **Stop word removal**: Removing common words that don't contribute much meaning\n",
    "4. **Lemmatization**: Reducing words to their base forms\n",
    "5. **Special handling for URLs, mentions, and COVID terminology**: Replacing or normalizing these elements\n",
    "\n",
    "### Modeling Approach\n",
    "\n",
    "We are implementing and comparing two main approaches:\n",
    "\n",
    "1. **Baseline Model**: A traditional machine learning approach using TF-IDF features with either Logistic Regression or Support Vector Machine (SVM). This serves as a benchmark for comparison.\n",
    "\n",
    "2. **Advanced Model**: A transformer-based approach using a fine-tuned BERT model, which has shown strong performance in various text classification tasks.\n",
    "\n",
    "### Unique Variations to Existing Methods\n",
    "\n",
    "Our implementation includes several novel modifications to standard approaches:\n",
    "\n",
    "1. **Domain-specific preprocessing**: Our preprocessing pipeline includes special handling for COVID-19 terminology and social media artifacts that standard NLP pipelines might miss.\n",
    "\n",
    "2. **Hybrid feature approach**: Beyond using just TF-IDF or word embeddings alone, we're experimenting with combining them with linguistic and statistical features like lexical diversity, sentiment scores, and readability metrics.\n",
    "\n",
    "3. **Cross-domain transfer learning**: We're developing a novel domain adaptation technique that uses COVID-19 data as a source domain and other health misinformation as a target domain, with a special focus on preserving general deception signals while reducing topic-specific biases.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "We will evaluate our models using accuracy, precision, recall, F1-score, and confusion matrices. We'll also perform cross-domain evaluation by testing our COVID-19-trained model on non-COVID health misinformation to assess generalization capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate/Preliminary Experiments & Results\n",
    "\n",
    "At this milestone, we have conducted several preliminary experiments and analyses:\n",
    "\n",
    "### Target Word Analysis\n",
    "\n",
    "We analyzed the frequency of specific target words (\"kills\", \"vaccine\", \"force\", \"death\", \"facebook\") in news articles. This analysis helps us understand linguistic patterns that might differentiate fake from real news. The results show that terms like \"vaccine\" and \"death\" appear more frequently in fake news articles, often in more sensationalist contexts.\n",
    "\n",
    "### Data Preparation Progress\n",
    "\n",
    "We have completed the following steps in data preparation:\n",
    "\n",
    "1. **Data Collection**: Acquired the COVID-19 Fake News Dataset and the CoAID collection\n",
    "2. **Initial Data Exploration**: Analyzed dataset structure, class distribution, and basic statistics\n",
    "3. **Text Preprocessing Pipeline**: Developed and tested preprocessing functions for cleaning text data\n",
    "4. **Target Word Analysis**: Analyzed frequency of specific words that might indicate fake news\n",
    "\n",
    "### Preliminary Model Testing\n",
    "\n",
    "We have designed the framework for our baseline models (TF-IDF with Logistic Regression or SVM) and are in the process of implementing our advanced BERT-based approach. Initial tests on small subsets of data show promising results, though comprehensive evaluation is still pending.\n",
    "\n",
    "Our baseline models have achieved the following preliminary results on a small validation set:\n",
    "- Logistic Regression with TF-IDF: 78.3% accuracy\n",
    "- SVM with TF-IDF: 79.5% accuracy\n",
    "\n",
    "These initial results suggest that even simple models can capture some patterns of misinformation, though we expect the advanced models to perform significantly better, especially on out-of-domain data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "\n",
    "Several research papers have addressed fake news detection, particularly in the context of health and COVID-19 misinformation. Here, we summarize five key papers and compare them to our approach:\n",
    "\n",
    "### 1. Patwa et al. (2021) - \"Fighting an Infodemic: COVID-19 Fake News Dataset\"\n",
    "\n",
    "This paper introduced a large-scale COVID-19 fake news dataset and tested various classical machine learning and deep learning models. Interestingly, they found that simpler models like SVM and logistic regression sometimes outperformed more complex architectures.\n",
    "\n",
    "**Comparison to our work**: \n",
    "- **Similarities**: We also evaluate both traditional ML and transformer-based approaches; we use similar evaluation metrics (accuracy, F1-score)\n",
    "- **Differences**: While Patwa et al. focused purely on COVID-19 misinformation, our project extends beyond this to test generalization to other health topics; we apply more sophisticated preprocessing specific to health domain terminology\n",
    "- **Our enhancements**: We're incorporating linguistic features beyond just word frequencies; our evaluation includes cross-domain performance metrics\n",
    "\n",
    "### 2. Cui & Lee (2020) - \"CoAID: COVID-19 Healthcare Misinformation Dataset\"\n",
    "\n",
    "This paper introduced the CoAID dataset, which combines news articles, social media posts, and user engagement metrics. A unique aspect of their work is the inclusion of social interaction data (likes, shares) and how these correlate with the spread of misinformation.\n",
    "\n",
    "**Comparison to our work**: \n",
    "- **Similarities**: We use the CoAID dataset as one of our data sources; we also consider multiple content types\n",
    "- **Differences**: We're focusing primarily on the textual content rather than social engagement metrics; we combine multiple datasets for more robust training\n",
    "- **Our enhancements**: Our hybrid feature approach might later incorporate social engagement signals; we're developing specialized preprocessing for social media content\n",
    "\n",
    "### 3. Shahi & Nandini (2020) - \"FakeCovid: A Multilingual Cross-Domain Fact Check News Dataset for COVID-19\"\n",
    "\n",
    "This paper compiled a multilingual dataset of fact-checked COVID-19 articles from numerous countries. Their focus was on cross-lingual and cross-domain analysis, examining how fake news varies across different cultural contexts.\n",
    "\n",
    "**Comparison to our work**: \n",
    "- **Similarities**: Both studies are concerned with the generalizability of fake news detection; both use fact-checked data\n",
    "- **Differences**: While we're currently focusing on English language content, their work studied multilingual aspects; our domain transfer is topic-based rather than language-based\n",
    "- **Our enhancements**: Our domain adaptation techniques specifically target health misinformation beyond COVID-19; we're experimenting with transfer learning approaches not covered in their work\n",
    "\n",
    "### 4. Kar et al. (2020) - \"No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection\"\n",
    "\n",
    "This study tackled multilingual fake tweet detection using a BERT-based framework. Their work demonstrated that even with limited labeled data, pre-trained models can achieve good results when fine-tuned appropriately.\n",
    "\n",
    "**Comparison to our work**: \n",
    "- **Similarities**: Like Kar et al., we're using a BERT-based approach for our advanced model; both studies work with relatively limited labeled data\n",
    "- **Differences**: Our focus is on domain transfer rather than language transfer; we're exploring both news articles and social media content\n",
    "- **Our enhancements**: We're implementing custom domain adaptation techniques not present in their work; our feature engineering includes linguistic markers specific to health misinformation\n",
    "\n",
    "### 5. Vijjali et al. (2020) - \"Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking\"\n",
    "\n",
    "This paper proposed an innovative two-stage approach: first retrieving relevant facts from a knowledge base, then using textual entailment to verify claims. This combines detection with automated fact-checking.\n",
    "\n",
    "**Comparison to our work**: \n",
    "- **Similarities**: Both approaches use transformer architectures for fake news detection; both aim to go beyond surface-level text classification\n",
    "- **Differences**: Our current approach is more focused on the detection stage, without their fact-checking component; we're more concerned with generalization across health topics\n",
    "- **Our enhancements**: Our preprocessing pipeline includes specialized handling of health terminology; our evaluation explicitly tests cross-domain performance; we're developing hybrid feature approaches combining statistical and semantic signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of Labor\n",
    "\n",
    "The project responsibilities are divided between team members as follows:\n",
    "\n",
    "**Santiago von Straussburg**:\n",
    "- Data collection and preprocessing\n",
    "- Implementation of the baseline models (TF-IDF with Logistic Regression/SVM)\n",
    "- Evaluation metrics development and analysis\n",
    "- Documentation and report writing\n",
    "\n",
    "**Kyle Parfait**:\n",
    "- Advanced model implementation (BERT-based approach)\n",
    "- Cross-domain transfer testing and analysis\n",
    "- Visualization of results\n",
    "- Code review and optimization\n",
    "\n",
    "Both team members collaborate on experimental design, interpretation of results, and the final project presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline\n",
    "\n",
    "The following outlines our planned steps and projected completion dates:\n",
    "\n",
    "1. **Complete Data Preprocessing** (April 20, 2025)\n",
    "   - Finalize text cleaning pipeline\n",
    "   - Merge datasets and create train/test splits\n",
    "   - Prepare non-COVID health misinformation test set\n",
    "\n",
    "2. **Finalize Baseline Models** (April 27, 2025)\n",
    "   - Implement and optimize TF-IDF with Logistic Regression\n",
    "   - Implement and optimize TF-IDF with SVM\n",
    "   - Compare performance and select best baseline\n",
    "\n",
    "3. **Implement BERT-based Model** (May 4, 2025)\n",
    "   - Fine-tune pre-trained BERT on COVID-19 dataset\n",
    "   - Optimize hyperparameters\n",
    "   - Implement memory-efficient training strategies\n",
    "\n",
    "4. **Conduct Cross-Domain Testing** (May 11, 2025)\n",
    "   - Evaluate models on non-COVID health misinformation\n",
    "   - Analyze error patterns and potential improvements\n",
    "   - Implement domain adaptation techniques if needed\n",
    "\n",
    "5. **Complete Final Analysis and Report** (May 18, 2025)\n",
    "   - Compile comprehensive evaluation results\n",
    "   - Create visualizations for key findings\n",
    "   - Write final report and prepare presentation\n",
    "\n",
    "6. **Project Presentation and Submission** (May 25, 2025)\n",
    "   - Finalize project presentation\n",
    "   - Complete and submit all deliverables\n",
    "   - Document code and ensure reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Patwa, P., Sharma, S., Pykl, S., Guptha, V., Kumari, G., Akhtar, M. S., Ekbal, A., Arora, A., & Chakraborty, T. (2021). Fighting an infodemic: COVID-19 fake news dataset. Communications and Network Security. https://arxiv.org/abs/2011.03327\n",
    "\n",
    "2. Cui, L., & Lee, D. (2020). CoAID: COVID-19 healthcare misinformation dataset. arXiv preprint. https://arxiv.org/abs/2006.00885\n",
    "\n",
    "3. Shahi, G. K., & Nandini, D. (2020). FakeCovid: A multilingual cross-domain fact check news dataset for COVID-19. arXiv preprint. https://arxiv.org/abs/2006.11343\n",
    "\n",
    "4. Kar, S., Bhardwaj, R., Samanta, S., & Bhagat, A. (2020). No rumours please! A multi-indic-lingual approach for COVID fake-tweet detection. arXiv preprint. https://arxiv.org/abs/2010.06906\n",
    "\n",
    "5. Vijjali, R., Potluri, P., Kumar, S., & Teki, S. (2020). Two stage transformer model for COVID-19 fake news detection and fact checking. arXiv preprint. https://arxiv.org/abs/2011.13253"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
